{
    "name": "root",
    "gauges": {
        "PaddleAgent.Policy.Entropy.mean": {
            "value": 1.3138439655303955,
            "min": 1.3072140216827393,
            "max": 1.449029803276062,
            "count": 644
        },
        "PaddleAgent.Policy.Entropy.sum": {
            "value": 21021.50390625,
            "min": 20175.12109375,
            "max": 39410.609375,
            "count": 644
        },
        "PaddleAgent.Step.mean": {
            "value": 6439276.0,
            "min": 9801.0,
            "max": 6439276.0,
            "count": 644
        },
        "PaddleAgent.Step.sum": {
            "value": 6439276.0,
            "min": 9801.0,
            "max": 6439276.0,
            "count": 644
        },
        "PaddleAgent.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": -0.008215474896132946,
            "min": -0.5563904047012329,
            "max": 0.7096096873283386,
            "count": 644
        },
        "PaddleAgent.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": -0.08215475082397461,
            "min": -53.377132415771484,
            "max": 109.989501953125,
            "count": 644
        },
        "PaddleAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.008215474896132946,
            "min": -0.5563904047012329,
            "max": 0.7096096873283386,
            "count": 644
        },
        "PaddleAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.08215475082397461,
            "min": -53.377132415771484,
            "max": 109.989501953125,
            "count": 644
        },
        "PaddleAgent.Environment.EpisodeLength.mean": {
            "value": 4999.0,
            "min": 54.72222222222222,
            "max": 4999.0,
            "count": 614
        },
        "PaddleAgent.Environment.EpisodeLength.sum": {
            "value": 39992.0,
            "min": 1866.0,
            "max": 45410.0,
            "count": 614
        },
        "PaddleAgent.Self-play.ELO.mean": {
            "value": 1200.0,
            "min": 1200.0,
            "max": 1200.0,
            "count": 560
        },
        "PaddleAgent.Self-play.ELO.sum": {
            "value": 1200.0,
            "min": 1200.0,
            "max": 192000.0,
            "count": 560
        },
        "PaddleAgent.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": -1.0,
            "max": 1.0,
            "count": 626
        },
        "PaddleAgent.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": -127.0,
            "max": 160.0,
            "count": 626
        },
        "PaddleAgent.Policy.ExtrinsicReward.mean": {
            "value": 0.0,
            "min": -1.0,
            "max": 1.0,
            "count": 626
        },
        "PaddleAgent.Policy.ExtrinsicReward.sum": {
            "value": 0.0,
            "min": -127.0,
            "max": 160.0,
            "count": 626
        },
        "PaddleAgent.Environment.GroupCumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 626
        },
        "PaddleAgent.Environment.GroupCumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 626
        },
        "PaddleAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 644
        },
        "PaddleAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 644
        },
        "PaddleAgent.Losses.PolicyLoss.mean": {
            "value": 0.016814393068974216,
            "min": 0.010784900786044696,
            "max": 0.025078051964131494,
            "count": 306
        },
        "PaddleAgent.Losses.PolicyLoss.sum": {
            "value": 0.016814393068974216,
            "min": 0.010784900786044696,
            "max": 0.025078051964131494,
            "count": 306
        },
        "PaddleAgent.Losses.ValueLoss.mean": {
            "value": 1.7894128272170444e-06,
            "min": 8.119684445883842e-07,
            "max": 0.045459867392977076,
            "count": 306
        },
        "PaddleAgent.Losses.ValueLoss.sum": {
            "value": 1.7894128272170444e-06,
            "min": 8.119684445883842e-07,
            "max": 0.045459867392977076,
            "count": 306
        },
        "PaddleAgent.Losses.BaselineLoss.mean": {
            "value": 1.7894128272170444e-06,
            "min": 8.119684445883842e-07,
            "max": 0.056555544336636863,
            "count": 306
        },
        "PaddleAgent.Losses.BaselineLoss.sum": {
            "value": 1.7894128272170444e-06,
            "min": 8.119684445883842e-07,
            "max": 0.056555544336636863,
            "count": 306
        },
        "PaddleAgent.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 306
        },
        "PaddleAgent.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 306
        },
        "PaddleAgent.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.2,
            "max": 0.20000000000000007,
            "count": 306
        },
        "PaddleAgent.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.2,
            "max": 0.20000000000000007,
            "count": 306
        },
        "PaddleAgent.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005,
            "max": 0.005000000000000001,
            "count": 306
        },
        "PaddleAgent.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005,
            "max": 0.005000000000000001,
            "count": 306
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1632023829",
        "python_version": "3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Users\\zhuan\\anaconda3\\envs\\mlagents-2\\Scripts\\mlagents-learn ./trainer_config.yaml --run-id 11",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1",
        "numpy_version": "1.20.3",
        "end_time_seconds": "1632052140"
    },
    "total": 28310.9769187,
    "count": 1,
    "self": 0.26294449999477365,
    "children": {
        "run_training.setup": {
            "total": 0.14251560000000008,
            "count": 1,
            "self": 0.14251560000000008
        },
        "TrainerController.start_learning": {
            "total": 28310.571458600003,
            "count": 1,
            "self": 33.551864301556634,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.263839799992361,
                    "count": 33,
                    "self": 8.263839799992361
                },
                "TrainerController.advance": {
                    "total": 28268.582019198453,
                    "count": 1621986,
                    "self": 34.17583019639278,
                    "children": {
                        "env_step": {
                            "total": 26130.890583500513,
                            "count": 1621986,
                            "self": 20660.89490530273,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 5445.964511099392,
                                    "count": 1621986,
                                    "self": 195.73316309776874,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 5250.231348001624,
                                            "count": 3243972,
                                            "self": 2407.1327498053374,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 2843.0985981962863,
                                                    "count": 3243972,
                                                    "self": 2843.0985981962863
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 24.03116709839086,
                                    "count": 1621985,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 28259.556938900634,
                                            "count": 1621985,
                                            "is_parallel": true,
                                            "self": 9725.212520300065,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.01968850000549871,
                                                    "count": 66,
                                                    "is_parallel": true,
                                                    "self": 0.006871800032502762,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.012816699972995949,
                                                            "count": 132,
                                                            "is_parallel": true,
                                                            "self": 0.012816699972995949
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 18534.324730100565,
                                                    "count": 1621985,
                                                    "is_parallel": true,
                                                    "self": 277.6757142992428,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 236.39853940034288,
                                                            "count": 1621985,
                                                            "is_parallel": true,
                                                            "self": 236.39853940034288
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 17087.92918030005,
                                                            "count": 1621985,
                                                            "is_parallel": true,
                                                            "self": 17087.92918030005
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 932.321296100929,
                                                            "count": 3243970,
                                                            "is_parallel": true,
                                                            "self": 332.0502184988933,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 600.2710776020357,
                                                                    "count": 6487940,
                                                                    "is_parallel": true,
                                                                    "self": 600.2710776020357
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2103.5156055015455,
                            "count": 1621985,
                            "self": 106.65601140136187,
                            "children": {
                                "process_trajectory": {
                                    "total": 467.7083534001955,
                                    "count": 1621985,
                                    "self": 464.5013016001991,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 3.2070517999964068,
                                            "count": 12,
                                            "self": 3.2070517999964068
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1529.1512406999882,
                                    "count": 306,
                                    "self": 933.857823499971,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 595.2934172000172,
                                            "count": 9228,
                                            "self": 595.2934172000172
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.1000010999850929e-06,
                    "count": 1,
                    "self": 1.1000010999850929e-06
                },
                "TrainerController._save_models": {
                    "total": 0.17373420000149054,
                    "count": 1,
                    "self": 0.008216999998694519,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.16551720000279602,
                            "count": 1,
                            "self": 0.16551720000279602
                        }
                    }
                }
            }
        }
    }
}